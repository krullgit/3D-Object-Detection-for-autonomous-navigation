# general train params
project_dir_base: "/home/makr/Documents/uni/TU/3.Master/experiments/own/tf_3dRGB_pc"
training : None # is just a placeholder and is set in the train.py directly 
model_id: "1" # This defines the naming of the newly trained model, if already exists it will count up by 1 recursively
# differentiate between input data
custom_dataset: True # if True, the datapipeline for the realsense 435i data is used

# general train params
epochs_total: 160 # how many epochs to train
load_weights: True
do_evaluate: True # If True, we will do an evaluation after each epoch during training 

# eval general params
measure_time: False
measure_time_extended: False
eval_model_id: "496" #  whats the name of the folder of the trained model
eval_checkpoint: "/model_weights_21.h5" # Option: [model_weights_temp, model_weights_0] # which checkpoint of the model we want to use. The number in "model_weights_0" defines the epoch 
# "no_annos_mode" in "eval_input_reader" must also be set

# eval production_mode params
production_mode: False # If true  we take new pointclouds from a realsense live stream
prediction_min_score: 0.3 # this is only used in production_mode = True # removes prediction scores lower than x

# input_reader general
cache : False  # do we have a buffer/cache (where is the difference?) // seems to overfloat the memory, so better set to False always 
shuffle_buffer_size : 1  # set how many (shuffle_buffer_size) datapoints are in the buffer where elements are randomly selected from
buffer_size : AUTOTUNE # how many datapoints are stored in buffer for the network / `prefetch` lets the dataset fetch batches in the background while the model is training.
iterate_samples_in_debug_mode: False  # Allows better debugging of data_loader.py # if True no tf dataset generator is created but the point clouds are preprocessed as usual
debug_save_points: False # if True the intermediate steps of the network should be saved to a folder

# Dataloader for training
train_input_reader:
  no_annos_mode: False # Option: [True, False] # True is there are no labels provided  
  img_list_and_infos_path : "/home/makr/Documents/data/pedestrian_3d_own/1/object/kitti_infos_train.pkl"
  dataset_root_path : "/home/makr/Documents/data/pedestrian_3d_own/1/object"

  # sampler
  sampler_info_path : "/home/makr/Documents/data/pedestrian_3d_own/1/object/kitti_dbinfos_train.pkl"
  sample_classes: ["Pedestrian"] # objects we want to randomly place inside the pointcloud 
  sample_max_nums: [2] # number of objects we want to randomly place inside the pointcloud 
  sampler_max_point_collision: 200 # maximum number of points in the point cloud the sampled object can overlap (take the same 3D space)
  sampler_min_point_collision: 1 # minumum number of points in the point cloud the sampled object must overlap (take the same 3D space)


  desired_objects : ["Pedestrian"] # these are the object we consoider in out dataloader pipeline

  num_point_features : 3 # defines how many features are given by he training data # 3 is minimum stands for x,y,z 
  feature_map_size :  [1,248,296] # [channel, width, height] for the input feature map
  batch_size : 2 # the batch size for training 

  # parameter for augmentation
  groundtruth_rotation_uniform_noise : [-0.15707963267, 0.15707963267] # per object
  groundtruth_localization_noise_std: [0.15, 0.15, 0.15] # per object
  global_random_rotation_range_per_object: [0, 0] # whole pointcloud
  global_rotation_uniform_noise: [-0.178539816, 0.178539816] # whole pointcloud
  global_scaling_uniform_noise: [0.95, 1.05] # whole pointcloud
  # global_loc_noise_std: [0.1, 0.1, 0.1] # whole pointcloud
  global_loc_noise_std: [0.1, 0.1, 0.2] # whole pointcloud 

  anchor_area_threshold: 1 

# Dataloader for evaluation
eval_input_reader: 
  no_annos_mode: True # Option: [True, False] # True is there are no labels provided. In this case the test set in img_list_and_infos_path_no_annos will be used
  img_list_and_infos_path : "/home/makr/Documents/data/pedestrian_3d_own/1/object/kitti_infos_val_sampled.pkl" 
  img_list_and_infos_path_no_annos : "/home/makr/Documents/data/pedestrian_3d_own/1/object/kitti_infos_val_live.pkl" 
  dataset_root_path : "/home/makr/Documents/data/pedestrian_3d_own/1/object"
  
  # sampler # in eval no sampler used so None
  sampler_info_path : None 
  sample_classes: None
  sample_max_nums: None
  sampler_max_point_collision: None
  sampler_min_point_collision: None 

  desired_objects : ["Pedestrian"] # these are the object we consoider in out dataloader pipeline # if changed also change num_class
  
  num_point_features : 3 # defines how many features are given by he training data # 3 is minimum stands for x,y,z 
  feature_map_size :  [1,248,296] # [channel, width, height] for the input feature map
  batch_size : 1 # the batch size for training 
  
  anchor_area_threshold: 1 

# model 
model:
  second:
    voxel_generator:
      #point_cloud_range : [0, -19.84, -2.5, 47.36, 19.84, 2.0] # in meter # outside this range points will be deleted (in the point to voxel assignment process) # is used for the grid_size, creating voxels and creating anchors
      point_cloud_range : [0, -9.92, -3.0, 23.68, 9.92, 3.0] # in meter # outside this range points will be deleted (in the point to voxel assignment process) # is used for the grid_size, creating voxels and creating anchors
      voxel_size : [0.08, 0.08, 6.0] # This is the size of the voxels beeing created # Z must be the same as the Z range in point_cloud_range # If Z too small points in height will be truncated
      max_number_of_points_per_voxel : 200 # max number of poits per voxel, they will be randomly sampled if to many
      max_number_of_voxels: 12000 # max number of voxels
    num_class: 1 # how many desired_objects we have 
    voxel_feature_extractor: # params for the PillarFeatureNet
      module_class_name: "PillarFeatureNet"
      num_filters: 128 #128 # 64 # output of the linear layer which encodes 8 features (without reflectance) to num_filters filters
      with_distance: false # not used

    # rpn
    rpn: 
      module_class_name: "RPN"
      layer_nums: [3, 5, 5] # defines the amount of layers per Block
      layer_strides: [1, 2, 2] # defines the strides per Block
      num_filters: [64, 128, 256] # defines num_filters per Block
      upsample_strides: [1, 2, 4] # defines upsample_strides per Block
      num_upsample_filters: [128, 128, 128] # defines num_upsample_filters per Block
      use_groupnorm: false
      num_groups: 32

    # Outputs 
    use_sigmoid_score: true # if true, use sigmoid for classification scores
    encode_background_as_zeros: true # Defines if background is labeled as 0 in the data_loader and training 
    encode_rad_error_by_sin: true # If True, the rotation is enocoded as sin(a - b) = sina*cosb-cosa*sinb 

    # Loss
    loss: 
      classification_loss:
        weighted_sigmoid_focal: # params for the focal loss in https://arxiv.org/pdf/1708.02002.pdf
          alpha: 0.25
          gamma: 2.0
          anchorwise_output: true
      localization_loss: # params for the localization loss
        weighted_smooth_l1:
          sigma: 3.0
          code_weight: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] # (This array is trainable in the net). It puts different emphasis on # [x, y, z, xdim, ydim, zdim, rad]
      classification_weight: 1.0 # Final Loss weight for classification
      #localization_weight: 2.0 # Final Loss weight for localization 
      localization_weight: 1.5 # Final Loss weight for localization
    # Loss general
    pos_class_weight: 1.0 # How the predictions for classification are weighted for objects
    neg_class_weight: 1.0 # How the predictions for classification are weighted for background
    loss_norm_type: NormByNumPositives # Defines Normalization for classification and registration weights
    # Loss direction classification
    use_direction_classifier: true # True for use the use_direction_classifier 
    #direction_loss_weight: 0.2 # Final Loss weight for direction 
    direction_loss_weight: 0.5 # Final Loss weight for direction

    # Postprocess
    post_center_limit_range: [0, -9.92, -3.0, 23.68, 9.92, 3.0]
    use_rotate_nms: false # Only false is implemented
    use_multi_class_nms: false # true is not implemented yet
    nms_pre_max_size: 10 # maximum number of prediction go to nms
    nms_post_max_size: 300 # maximum number of prediction out from nms
    nms_score_threshold: 0.0 # minimum prediction probability, everything below is deleted # is set to 0.0 since the implentation is slow
    nms_iou_threshold: 0.5 # if 2D iou from first prediction to other prediction is greater than this the other prediction(s) gets deleted (regular nms logic)
    num_point_features: 3 # Options[3,4] # 4 for Kitti, 3 for custom 
    without_reflectivity: false

    target_assigner: # params for the target assigner and anchor generator in load_data.py
      anchor_generators:  
        anchor_generator_stride:
          sizes: [0.6, 0.8, 1.73] # width, length, and height of anchors # Warum ist hier auch die höhe definiert?
          strides: [0.08, 0.08, 0.0] # z_stride will be ignored since anchors have only one height # stride for the anchors (detemermines therefore the overlap of anchors since "sizes" is bigger than strides), this should therefore match "voxel_size": I dont know if it would work to have different strides and voxel_size
          offsets: [0.08, -9.92, -1.465] # this defines the center of all anchors
          rotations: [0, 1.57] # 0, pi/2
          matched_threshold : 0.5 # iou greater than matched_threshold will be treated as positives.
          unmatched_threshold : 0.35 # iou smaller than unmatched_threshold will be treated as negatives.

      sample_positive_fraction : None # [0-1] float or None. if not None, we will try to keep ratio of pos/neg equal to positive_fraction when sample. if there is not enough positives, it fills the rest with negatives
      rpn_batch_size : 512 
        
# Optimizer 
train_config: 
  optimizer: 
    adam_optimizer: 
      learning_rate: 
        exponential_decay_learning_rate: 
          initial_learning_rate: 0.002 # learning rate we start with
          decay_steps: 27840 # 4800 for batch size 2 and 2400 samples #27840 # 1856 steps per epoch * 15 epochs # TODO umrechnen auf batch_size 1
          decay_factor: 0.8
          staircase: true # if false, there will be   a smooth transition from one learning rate to the next learning rate
      weight_decay: 0.0001
  net_metrics_steps: 500 # after how many steps (batch iteration) the metrics eval must be shown
  
